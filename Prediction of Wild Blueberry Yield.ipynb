{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0376fae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\dask\\dataframe\\backends.py:187: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\dask\\dataframe\\backends.py:187: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\dask\\dataframe\\backends.py:187: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1848\\2666495012.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_sequential_feature_selection\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplot_sfs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scikeras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TensorFlow is not installed. \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTF_VERSION_ERR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    417\u001b[0m \"\"\"\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_service_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# ==============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \"\"\"\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sparse_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdoc_controls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0m_np_bfloat16\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_bfloat16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_bfloat16_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0m_np_float8_e4m3fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_float8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_float8_e4m3fn_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0m_np_float8_e5m2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_float8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_float8_e5m2_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a975de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_combine_data = pd.read_csv('train_combine.csv')\n",
    "\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a3f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combine_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81544826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing Skew of Attribute Distribution\n",
    "skew_value = train_data.skew()\n",
    "\n",
    "skewness_values = pd.DataFrame({\n",
    "    'Variable': train_data.columns,\n",
    "    'Skewness': skew_value\n",
    "})\n",
    "plt.figure(figsize=(50,8))\n",
    "# Plot the skewness values using a barplot\n",
    "sns.barplot(x='Variable', y='Skewness', data=skewness_values)\n",
    "\n",
    "# Add labels and a title to the plot\n",
    "\n",
    "plt.xlabel(\"Features\",size=15)\n",
    "plt.ylabel(\"Skewness\",size=15)\n",
    "plt.title(\"Skewness of Variables in bDiabetes Dataset\",size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histrogram for each attribute in dataset\n",
    "train_data.hist(figsize=(20,20),column=train_data.drop(columns=['id']).columns,color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_combine_data.drop(columns=['id','yield'])\n",
    "y = train_combine_data[['yield']]\n",
    "X_test = test_data.drop(columns=['id']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2a210",
   "metadata": {},
   "source": [
    "### Feature Selection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906fda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing Correlation between attributes\n",
    "correlations = round(X.corr(),4)\n",
    "correlations # 1 represent full positive correlation, -1 represent negative correllation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe392c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(correlations, annot=True,cmap ='RdBu_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over bottom diagonal of correlation matrix\n",
    "threshold = 0.9\n",
    "high_corr = []\n",
    "for i in range(len(correlations.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlations.iloc[i, j]) > threshold:\n",
    "            colname = correlations.columns[i]\n",
    "            high_corr.append(colname)\n",
    "            \n",
    "set(high_corr)\n",
    "\n",
    "# remove highly correlated features\n",
    "# df.drop(high_corr, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features and targets together for checking correlation\n",
    "X_y = X.copy()\n",
    "X_y['yield'] = y\n",
    "X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf891aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = X_y.corr()\n",
    "correlation_target = correlation[['yield']].drop(labels=['yield'])\n",
    "correlation_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94882c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"fruit_seed\"] = X[\"fruitset\"] * X[\"seeds\"]\n",
    "X[\"pollinators\"] = X[\"honeybee\"] + X[\"bumbles\"] + X[\"andrena\"] + X[\"osmia\"]\n",
    "X = X.drop(columns=['RainingDays', 'MaxOfUpperTRange', 'MinOfUpperTRange', 'AverageOfUpperTRange', 'MaxOfLowerTRange', 'MinOfLowerTRange', 'honeybee', 'bumbles', 'andrena' , 'osmia'])\n",
    "\n",
    "X_test[\"fruit_seed\"] = X_test[\"fruitset\"] * X_test[\"seeds\"]\n",
    "X_test[\"pollinators\"] = X_test[\"honeybee\"] + X_test[\"bumbles\"] + X_test[\"andrena\"] + X_test[\"osmia\"]\n",
    "X_test = X_test.drop(columns=['RainingDays', 'MaxOfUpperTRange', 'MinOfUpperTRange', 'AverageOfUpperTRange', 'MaxOfLowerTRange', 'MinOfLowerTRange', 'honeybee', 'bumbles', 'andrena' , 'osmia'])\n",
    "\n",
    "print(X.columns)\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_original = X.drop(columns=['AverageOfLowerTRange','AverageOfUpperTRange','MaxOfLowerTRange','MinOfLowerTRange','MinOfUpperTRange'])\n",
    "# X_test_original = X_test.drop(columns=['AverageOfLowerTRange','AverageOfUpperTRange','MaxOfLowerTRange','MinOfLowerTRange','MinOfUpperTRange'])\n",
    "# print(X_original.columns)\n",
    "# print(X_test_original.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97633fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_scaler = pd.DataFrame(sc.fit_transform(X),columns=[X.columns])\n",
    "X_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8638b31",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(model,x_data):\n",
    "    \n",
    "    # Ensure the random distributions are same when execute \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    sfs = SFS(model,\n",
    "          k_features=8,\n",
    "          forward=True,\n",
    "          floating=False,\n",
    "          scoring='neg_mean_absolute_error',\n",
    "          cv=3)\n",
    "    \n",
    "    sfs.fit(x_data, y)\n",
    "    \n",
    "    print('Feature selection: \\n\\n')\n",
    "    for idx, score in sfs.subsets_.items():\n",
    "        print(idx,':', score, '\\n')\n",
    "    \n",
    "    print('Model MAE: \\n\\n')\n",
    "    for idx, score in sfs.subsets_.items():\n",
    "        print(idx,':', -1 * score['avg_score'].round(4))  # multiply by -1 to convert back to MAE score\n",
    "\n",
    "    \n",
    "    plot_sfs(sfs.get_metric_dict())\n",
    "    plt.grid()\n",
    "    plt.title('Accuracy vs Number of Features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(X,y,test_size=.2,random_state=36,shuffle=True)\n",
    "\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae2ca0",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_model = XGBRegressor()\n",
    "\n",
    "# feature_selection(xgboost_model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e0367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data = X[['clonesize', 'honeybee', 'bumbles', 'andrena', 'osmia', 'MaxOfUpperTRange', 'RainingDays', 'fruitset', 'fruitmass', 'seeds']]\n",
    "# min_mae_xgboost = []\n",
    "\n",
    "# for i in range(42):\n",
    "#     features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=i,shuffle=True)\n",
    "\n",
    "#     xgboost_model = XGBRegressor(subsample= 0.7, \n",
    "#                                  reg_lambda=0.1, \n",
    "#                                  reg_alpha=0.1, \n",
    "#                                  objective='reg:squarederror', \n",
    "#                                  n_estimators=1000, \n",
    "#                                  min_child_weight=5, \n",
    "#                                  max_depth= 4, \n",
    "#                                  learning_rate= 0.01, \n",
    "#                                  gamma=0.2, \n",
    "#                                  eval_metric='mae', \n",
    "#                                  colsample_bytree=0.9)\n",
    "\n",
    "#     xgboost_model.fit(features_train, labels_train)\n",
    "#     predicted = xgboost_model.predict(features_test)\n",
    "#     mae = mean_absolute_error(labels_test, predicted)\n",
    "#     min_mae_xgboost.append(mae)\n",
    "\n",
    "# for i,value in enumerate(min_mae_xgboost):\n",
    "#     if value == min(min_mae_xgboost):\n",
    "#         print(\"Mean Absolute Error:\", min(min_mae_xgboost), 'random_state:', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e476bd",
   "metadata": {},
   "source": [
    "### LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_model = LGBMRegressor()\n",
    "\n",
    "# feature_selection(lgbm_model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data = X[['clonesize', 'honeybee', 'bumbles', 'andrena', 'osmia', 'MaxOfUpperTRange', 'RainingDays', 'fruitset', 'fruitmass', 'seeds']]\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=36,shuffle=True)\n",
    "\n",
    "\n",
    "# lgbm_model = LGBMRegressor(subsample= 0.9, \n",
    "#                            reg_lambda=0, \n",
    "#                            reg_alpha= 0.3, \n",
    "#                            objective = 'mae', \n",
    "#                            num_leaves = 64, \n",
    "#                            n_estimators= 1000, \n",
    "#                            min_child_weight= 15, \n",
    "#                            max_depth= 5, \n",
    "#                            learning_rate= 0.05,\n",
    "#                            colsample_bytree= 0.9, \n",
    "#                            force_col_wise= True\n",
    "#                           )\n",
    "\n",
    "# parameters = {\n",
    "#               'min_child_samples':[25,20,15,10,5],\n",
    "#               'subsample_freq':[0,2,4,6,8,10],\n",
    "#               'max_bin':[128,150,200,255],\n",
    "#             }\n",
    "\n",
    "# grid = GridSearchCV(lgbm_model,parameters,scoring='neg_mean_absolute_error',cv=3)\n",
    "# grid.fit(features_train, labels_train)\n",
    "\n",
    "# print(\"Best parameters:\", grid.best_params_)\n",
    "# print(\"Best score of training data:\", round(grid.best_score_*100,2), \"%\\n\")\n",
    "\n",
    "# # predict on test data with best hyperparameters\n",
    "# y_pred = grid.predict(features_test)\n",
    "\n",
    "# # calculate MAE on test data with best hyperparameters\n",
    "# mae = mean_absolute_error(labels_test, y_pred)\n",
    "# print(\"Test MAE with Best Hyperparameters: \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9605452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data = X[['clonesize', 'AverageOfLowerTRange', 'AverageRainingDays', 'fruitset',\n",
    "#        'fruitmass', 'seeds', 'fruit_seed', 'pollinators']]\n",
    "# min_mae_lgbm = []\n",
    "\n",
    "# for i in range(42):\n",
    "    \n",
    "#     features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=i,shuffle=True)\n",
    "#     lgbm_model = LGBMRegressor(subsample= 0.9, \n",
    "#                                reg_lambda=0, \n",
    "#                                reg_alpha= 0.3, \n",
    "#                                objective = 'mae', \n",
    "#                                num_leaves = 64, \n",
    "#                                n_estimators= 1000, \n",
    "#                                min_child_weight= 15, \n",
    "#                                max_depth= 5, \n",
    "#                                learning_rate= 0.05,\n",
    "#                                colsample_bytree= 0.9, \n",
    "#                                force_col_wise= True,\n",
    "#                               )\n",
    "\n",
    "#     lgbm_model.fit(features_train, labels_train)\n",
    "#     predicted = lgbm_model.predict(features_test)\n",
    "#     mae = mean_absolute_error(labels_test, predicted)\n",
    "#     min_mae_lgbm.append(mae)\n",
    "    \n",
    "# for i,value in enumerate(min_mae_lgbm):\n",
    "#     if value == min(min_mae_lgbm):\n",
    "#         print(\"Mean Absolute Error:\", min(min_mae_lgbm), 'random_state:', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a364d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X[['clonesize', 'AverageOfLowerTRange', 'AverageRainingDays', 'fruitset',\n",
    "       'fruitmass', 'seeds', 'fruit_seed', 'pollinators']]\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=1,shuffle=True)\n",
    "\n",
    "lgbm_model_2 = LGBMRegressor(subsample= 0.9, \n",
    "                               reg_lambda=0, \n",
    "                               reg_alpha= 0.3, \n",
    "                               objective = 'mae', \n",
    "                               num_leaves = 64, \n",
    "                               n_estimators= 1000, \n",
    "                               min_child_weight= 15, \n",
    "                               max_depth= 5, \n",
    "                               learning_rate= 0.05,\n",
    "                               colsample_bytree= 0.9, \n",
    "                               force_col_wise= True,\n",
    "                              )\n",
    "\n",
    "lgbm_model_2.fit(features_train, labels_train)\n",
    "lgbm_predicted_2 = lgbm_model_2.predict(features_test)\n",
    "lgbm_mae_2 = mean_absolute_error(labels_test, lgbm_predicted_2)\n",
    "print(lgbm_mae_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bca58e",
   "metadata": {},
   "source": [
    "## CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d28ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cat_model = CatBoostRegressor(verbose=False)\n",
    "\n",
    "# feature_selection(cat_model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d7ad9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_model = CatBoostRegressor(verbose=False, \n",
    "                                  subsample=0.7,\n",
    "                                  random_strength=0.1, \n",
    "                                  loss_function='MAE', \n",
    "                                  learning_rate=0.05, \n",
    "                                  l2_leaf_reg=1, \n",
    "                                  iterations=1000,\n",
    "                                  depth= 16, \n",
    "                                  colsample_bylevel= 0.9, \n",
    "                                  grow_policy=\"Lossguide\",\n",
    "                                  border_count=980,\n",
    "                                  max_leaves=35\n",
    "                               )\n",
    "                               \n",
    "\n",
    "parameters = {\n",
    "                 'max_leaves':[x for x in range(20,40,1)]\n",
    "            }\n",
    "\n",
    "grid = GridSearchCV(cat_model,parameters,scoring='neg_mean_absolute_error',cv=3)\n",
    "grid.fit(features_train, labels_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score of training data:\", round(grid.best_score_*100,2), \"%\\n\")\n",
    "\n",
    "# predict on test data with best hyperparameters\n",
    "y_pred = grid.predict(features_test)\n",
    "\n",
    "# calculate MAE on test data with best hyperparameters\n",
    "mae = mean_absolute_error(labels_test, y_pred)\n",
    "print(\"Test MAE with Best Hyperparameters: \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d093c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X[['clonesize', 'AverageOfLowerTRange', 'AverageRainingDays', 'fruitset',\n",
    "       'fruitmass', 'seeds', 'fruit_seed', 'pollinators']]\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=36,shuffle=True)\n",
    "\n",
    "# cb_params = {\n",
    "# 'verbose': False, 'subsample': 0.5, 'random_strength': 0.05, 'loss_function': 'MAE', 'learning_rate': 0.05, 'l2_leaf_reg': 0, 'iterations': 1000, 'grow_policy': 'Lossguide', 'depth': 16, 'colsample_bylevel': 0.7, 'bagging_temperature': 0.1\n",
    "#         }\n",
    "# cat_model_2 = CatBoostRegressor(**cb_params)\n",
    "cat_model_2 = CatBoostRegressor(verbose=False, \n",
    "                                  subsample=0.7,\n",
    "                                  random_strength=0.1, \n",
    "                                  loss_function='MAE', \n",
    "                                  learning_rate=0.05, \n",
    "                                  l2_leaf_reg=1, \n",
    "                                  iterations=1000,\n",
    "                                  depth= 16, \n",
    "                                  colsample_bylevel= 0.9, \n",
    "                                  grow_policy=\"Lossguide\",\n",
    "                                  border_count=980,\n",
    "                                  max_leaves=31\n",
    "                               )\n",
    "\n",
    "\n",
    "cat_model_2.fit(features_train, labels_train)\n",
    "cat_predicted_2 = cat_model_2.predict(features_test)\n",
    "cat_mae_2 = mean_absolute_error(labels_test, cat_predicted_2)\n",
    "print(cat_mae_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import StackingRegressor\n",
    "# from sklearn.linear_model import LinearRegression,Ridge\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# X_data = X[['clonesize', 'AverageOfLowerTRange', 'AverageRainingDays', 'fruitset',\n",
    "#        'fruitmass', 'seeds', 'fruit_seed', 'pollinators']]\n",
    "\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=36,shuffle=True)\n",
    "\n",
    "# cat_model_2 = CatBoostRegressor(verbose=False, \n",
    "#                                   subsample=0.7,\n",
    "#                                   random_strength=0.1, \n",
    "#                                   loss_function='MAE', \n",
    "#                                   learning_rate=0.05, \n",
    "#                                   l2_leaf_reg=1, \n",
    "#                                   iterations=1000,\n",
    "#                                   depth= 16, \n",
    "#                                   colsample_bylevel= 0.9, \n",
    "#                                   grow_policy=\"Lossguide\",\n",
    "#                                   border_count=980\n",
    "#                                )\n",
    "\n",
    "# lgbm_model_2 = LGBMRegressor(subsample= 0.9, \n",
    "#                                reg_lambda=0, \n",
    "#                                reg_alpha= 0.3, \n",
    "#                                objective = 'mae', \n",
    "#                                num_leaves = 64, \n",
    "#                                n_estimators= 1000, \n",
    "#                                min_child_weight= 15, \n",
    "#                                max_depth= 5, \n",
    "#                                learning_rate= 0.05,\n",
    "#                                colsample_bytree= 0.9, \n",
    "#                                force_col_wise= True,\n",
    "#                               )\n",
    "\n",
    "# meta_model_list = [LinearRegression(), CatBoostRegressor(),Ridge(alpha=1.0),GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)]\n",
    "# meta_model_1 = LinearRegression(),\n",
    "# meta_model_2 = CatBoostRegressor(verbose=False)\n",
    "# meta_model_3 = Ridge(alpha=1.0)\n",
    "# meta_model_4 = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "# print(meta_model_list)\n",
    "\n",
    "\n",
    "# for i in meta_model_list:\n",
    "\n",
    "#     stacked_model = StackingRegressor(\n",
    "#         estimators=[('cat', cat_model_2), ('lgbm', lgbm_model_2)],\n",
    "#         final_estimator=i\n",
    "#     )\n",
    "\n",
    "#     stacked_model.fit(features_train, labels_train)\n",
    "#     stacked_predicted = stacked_model.predict(features_test)\n",
    "#     stacked_mae = mean_absolute_error(labels_test, stacked_predicted)\n",
    "#     print(stacked_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# X_data = X[['clonesize', 'AverageOfLowerTRange', 'AverageRainingDays', 'fruitset',\n",
    "#        'fruitmass', 'seeds', 'fruit_seed', 'pollinators']]\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=36,shuffle=True)\n",
    "\n",
    "# cat_model_2 = CatBoostRegressor(verbose=False, \n",
    "#                                   subsample=0.7,\n",
    "#                                   random_strength=0.1, \n",
    "#                                   loss_function='MAE', \n",
    "#                                   learning_rate=0.05, \n",
    "#                                   l2_leaf_reg=1, \n",
    "#                                   iterations=1000,\n",
    "#                                   depth= 16, \n",
    "#                                   colsample_bylevel= 0.9, \n",
    "#                                   grow_policy=\"Lossguide\",\n",
    "#                                   border_count=980\n",
    "#                                )\n",
    "\n",
    "# lgbm_model_2 = LGBMRegressor(subsample= 0.9, \n",
    "#                                reg_lambda=0, \n",
    "#                                reg_alpha= 0.3, \n",
    "#                                objective = 'mae', \n",
    "#                                num_leaves = 64, \n",
    "#                                n_estimators= 1000, \n",
    "#                                min_child_weight= 15, \n",
    "#                                max_depth= 5, \n",
    "#                                learning_rate= 0.05,\n",
    "#                                colsample_bytree= 0.9, \n",
    "#                                force_col_wise= True,\n",
    "#                               )\n",
    "\n",
    "\n",
    "# meta_model_1 = LinearRegression()\n",
    "\n",
    "# stacked_model = StackingRegressor(\n",
    "#         estimators=[('cat', cat_model_2), ('lgbm', lgbm_model_2)],\n",
    "#         final_estimator=meta_model_1\n",
    "#     )\n",
    "\n",
    "# stacked_model.fit(features_train, labels_train)\n",
    "# stacked_predicted = stacked_model.predict(features_test)\n",
    "# stacked_mae = mean_absolute_error(labels_test, stacked_predicted)\n",
    "# print(stacked_mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data = X_original[['clonesize', 'AverageOfLowerTRange', 'AverageRainingDays', 'fruitset',\n",
    "#        'fruitmass', 'seeds', 'fruit_seed', 'pollinators']]\n",
    "\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=36)\n",
    "\n",
    "# cat_model_3 = CatBoostRegressor(verbose=False, \n",
    "#                                   subsample=0.7, \n",
    "#                                   random_strength=0.1, \n",
    "#                                   loss_function='MAE', \n",
    "#                                   learning_rate=0.05, \n",
    "#                                   l2_leaf_reg=1, \n",
    "#                                   iterations=1010, \n",
    "#                                   depth= 16, \n",
    "#                                   colsample_bylevel= 0.9, \n",
    "#                                   grow_policy=\"Lossguide\",\n",
    "#                                   border_count=1000,\n",
    "#                                   leaf_estimation_iterations=1,\n",
    "#                                   one_hot_max_size=1  \n",
    "#                                )\n",
    "\n",
    "# cat_model_3.fit(features_train, labels_train)\n",
    "# cat_predicted_3 = cat_model_3.predict(features_test)\n",
    "# cat_mae_3 = mean_absolute_error(labels_test, cat_predicted_3)\n",
    "# print(cat_mae_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b524c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data = X[['clonesize', 'AverageOfLowerTRange', 'AverageRainingDays', 'fruitset',\n",
    "#        'fruitmass', 'seeds', 'fruit_seed', 'pollinators']]\n",
    "\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=36,shuffle=True)\n",
    "\n",
    "# # cb_params = {\n",
    "# # 'verbose': False, 'subsample': 0.5, 'random_strength': 0.05, 'loss_function': 'MAE', 'learning_rate': 0.05, 'l2_leaf_reg': 0, 'iterations': 1000, 'grow_policy': 'Lossguide', 'depth': 16, 'colsample_bylevel': 0.7, 'bagging_temperature': 0.1\n",
    "# #         }\n",
    "# # cat_model_2 = CatBoostRegressor(**cb_params)\n",
    "# cat_model_2 = CatBoostRegressor(verbose=False, \n",
    "#                                   subsample=0.7,\n",
    "#                                   random_strength=0.1, \n",
    "#                                   loss_function='MAE', \n",
    "#                                   learning_rate=0.05, \n",
    "#                                   l2_leaf_reg=1.001, \n",
    "#                                   iterations=980,\n",
    "#                                   depth= 16, \n",
    "#                                   colsample_bylevel= 0.9, \n",
    "#                                   grow_policy=\"Lossguide\",\n",
    "#                                   border_count=980\n",
    "#                                )\n",
    "\n",
    "\n",
    "# cat_model_2.fit(features_train, labels_train)\n",
    "# cat_predicted_2 = cat_model_2.predict(features_test)\n",
    "# cat_mae_2 = mean_absolute_error(labels_test, cat_predicted_2)\n",
    "# print(cat_mae_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a54e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data = X[['clonesize', 'honeybee', 'bumbles', 'osmia', 'MaxOfUpperTRange', 'AverageRainingDays', 'fruitset', 'fruitmass', 'seeds']]\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(X_data,y,test_size=.2,random_state=6,shuffle=True)\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(InputLayer(input_shape=(X.shape[1],)))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# opt = Adam(learning_rate=0.01)\n",
    "# model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n",
    "\n",
    "# model.fit(features_train,labels_train,batch_size=20, epochs=40, verbose=0)\n",
    "# #evaluate the model on the test data\n",
    "# val_mse, val_mae = model.evaluate(features_test, labels_test, verbose=0)\n",
    "\n",
    "# print(\"MAE: \", val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0555a42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def do_grid_search():\n",
    "    \n",
    "#     batch_size = [20, 40, 60]\n",
    "#     epochs = [10, 20, 30, 40, 50]\n",
    "#     model = KerasRegressor(build_fn=design_model())\n",
    "#     param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "#     grid = GridSearchCV(estimator = model, param_grid=param_grid, scoring = make_scorer(mean_squared_error, greater_is_better=False),return_train_score = True)\n",
    "#     grid_result = grid.fit(features_train, labels_train, verbose = 0)\n",
    "#     print(grid_result)\n",
    "#     print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# #     means = grid_result.cv_results_['mean_test_score']\n",
    "# #     stds = grid_result.cv_results_['std_test_score']\n",
    "# #     params = grid_result.cv_results_['params']\n",
    "# #     for mean, stdev, param in zip(means, stds, params):\n",
    "# #         print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# do_grid_search()\n",
    "\n",
    "# # model.fit(X_train,y_train,batch_size=10, epochs=40, verbose=0)\n",
    "# # #evaluate the model on the test data\n",
    "# # val_mse, val_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# # print(\"MAE: \", val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdab631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train,y_train,batch_size=20, epochs=10, verbose=0)\n",
    "# #evaluate the model on the test data\n",
    "# val_mse, val_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# print(\"MAE: \", val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe71337",
   "metadata": {},
   "source": [
    "### Write Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb16da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y\n",
    "X_test = X_test\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.columns)\n",
    "print(X_test.columns)\n",
    "final_model = cat_model_2.fit(X_train,y_train)\n",
    "final_predicted = final_model.predict(X_test)\n",
    "column1 = test_data['id']\n",
    "column2 = list(final_predicted)\n",
    "dataset=pd.DataFrame({'id':column1,'yield':column2})\n",
    "dataset.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b338013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b2aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
